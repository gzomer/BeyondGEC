{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "laughing-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = '' # Working dir\n",
    "DATA_DIR = f'{BASE_DIR}data/'\n",
    "MODELS_DIR = f'{BASE_DIR}models/'\n",
    "RESULTS_DIR = f'{BASE_DIR}results'\n",
    "\n",
    "MODEL_NAME = 'l1-aware-t5'\n",
    "AGG_FOLDER = f'{RESULTS_DIR}{MODEL_NAME}/aggregated/'\n",
    "CACHE_DIR = f'{BASE_DIR}cache/'\n",
    "ALIGNMENT_FOLDER = f'{CACHE_DIR}/alignments/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abroad-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "logical-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "from transformers import T5Tokenizer\n",
    "import torch\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-brighton",
   "metadata": {},
   "source": [
    "# Model for processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sudden-inspiration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compare_improve(sentence,num_outputs=1):\n",
    "    print(\"BEFORE:\", sentence)\n",
    "    outputs = generate(model, IMPROVE_TOKEN + sentence, num_outputs)\n",
    "    print(\"\\nAFTER :\\n-\", '\\n- '.join([sent.strip() for sent in outputs]))\n",
    "    \n",
    "    return outputs\n",
    "\n",
    "def generate_batch(model, sentences, num_outputs=1, length=100):\n",
    "    encodings = tokenizer(sentences, return_tensors='pt', padding=True).to(device=device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(encodings['input_ids'], \n",
    "                                max_length=length, num_beams=5, \n",
    "                                num_return_sequences=num_outputs,\n",
    "                                early_stopping=False)    \n",
    "        return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "    \n",
    "def generate(model, start, num_outputs=1, length=100):\n",
    "    inputs_ids = tokenizer.encode(start, return_tensors='pt').to(device=device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(inputs_ids, \n",
    "                                max_length=length, num_beams=5, \n",
    "                                num_return_sequences=num_outputs,\n",
    "                                early_stopping=False)    \n",
    "        return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n",
    "            \n",
    "def process_sentences(model, sentences, batch_size=8):\n",
    "    parsed_sentences = []\n",
    "    \n",
    "    def divide_chunks(l, n):       \n",
    "        for i in range(0, len(l), n):  \n",
    "            yield l[i:i + n] \n",
    "    \n",
    "    total = math.ceil(len(sentences)/batch_size)\n",
    "    for batch in tqdm(divide_chunks(sentences, batch_size), total=total):\n",
    "        \n",
    "        batch_sents = [IMPROVE_TOKEN+item for item in batch]\n",
    "        \n",
    "        outputs = generate_batch(model, batch_sents, 1)\n",
    "    \n",
    "        parsed_sentences.extend(outputs)\n",
    "        \n",
    "    return parsed_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "announced-marshall",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def save_split_files(data, base_output, tokenize=True):\n",
    "    \n",
    "    export_data = defaultdict(list)\n",
    "    for item in data:\n",
    "        for key in item:\n",
    "            if tokenize:\n",
    "                export_data[key].append(' '.join(word_tokenize(item[key])))\n",
    "            else:\n",
    "                export_data[key].append(item[key])\n",
    "    \n",
    "    for key in export_data:\n",
    "        if os.path.exists(f'{base_output}-{key}.txt'):\n",
    "            continue\n",
    "        with open(f'{base_output}-{key}.txt', 'w', encoding='utf8') as f:\n",
    "            f.write('\\n'.join(export_data[key]))                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "decimal-spectacular",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multi_tokens(files, languages=['es', 'de', 'fr', 'pt']):\n",
    "    multi_lingual_token_files = []\n",
    "\n",
    "    for language in languages:\n",
    "        for file in files:\n",
    "            base_file = file.split('.')[0]\n",
    "            multi_lingual_token_files.append(f'{base_file}-token-{language}.json') \n",
    "    return multi_lingual_token_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "trying-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from os import listdir\n",
    "\n",
    "def save_multi_files(files, base_folder):\n",
    "    for file in files:\n",
    "        base_file = file.split('.')[0]\n",
    "        with open(f'{base_folder}/{file}','r') as f:\n",
    "            data_sentences = json.loads(f.read())\n",
    "        \n",
    "        save_split_files([\n",
    "            {\n",
    "                'orig': item['orig'],\n",
    "                'improved': item['improved'][0]\n",
    "            }\n",
    "            for item in data_sentences]\n",
    "            , f'{base_folder}/{base_file}',tokenize=False)    \n",
    "    \n",
    "def split_models_files(models, files):   \n",
    "    for model_version in models:\n",
    "        base_folder = f'{RESULTS_DIR}{MODEL_NAME}/{model_version}/processed'\n",
    "        save_multi_files(files, base_folder)\n",
    "        \n",
    "def find_files_and_split(models):    \n",
    "    for model_version in models:\n",
    "        base_folder = f'{RESULTS_DIR}{MODEL_NAME}/{model_version}/processed'\n",
    "        files = [file for file in listdir(base_folder) if '.json' in file]\n",
    "        split_models_files([model_version], files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "common-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_list = [ \n",
    "    't5sm-l1aware-multi-s260-v1',\n",
    "    't5lg-l1aware-multi-s260-v1',\n",
    "]\n",
    "\n",
    "find_files_and_split(models_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-ladder",
   "metadata": {},
   "source": [
    "# Grammaticality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "conscious-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForSequenceClassification, RobertaTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "outside-protocol",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base')\n",
    "robert_cola = RobertaForSequenceClassification.from_pretrained(MODELS_DIR+'roberta-cola-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "unusual-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning.metrics import functional as FM\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "class LMClassifierInference(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, model, tokenizer, labels):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.labels = labels        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.model.eval()\n",
    "        self.model.cuda()\n",
    "        \n",
    "        input_ids = tokenizer.encode(x, return_tensors='pt').to('cuda')\n",
    "        outputs = self.model(input_ids)\n",
    "        prob = F.softmax(outputs.logits.detach(), dim=1).cpu().numpy()[0].tolist()\n",
    "        \n",
    "        return {label: prob[index]  for index, label in enumerate(self.labels)}[self.labels[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "designed-device",
   "metadata": {},
   "outputs": [],
   "source": [
    "cola_model = LMClassifierInference(robert_cola, tokenizer, ['wrong', 'correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "discrete-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_grammaticality(file, limit=None, detokenize=False, output='grammar', input_dir=MODEL_VERSION_RESULTS_DIR_PROCESSED, output_dir=MODEL_VERSION_RESULTS_DIR_METRICS, metric_version=None):\n",
    "    process_file_metric(file, cola_model, output, limit=limit, detokenize=detokenize, input_dir=input_dir, output_dir=output_dir, metric_version=metric_version)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "married-color",
   "metadata": {},
   "source": [
    "# SLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "mathematical-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "potential-talent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "\n",
    "class UnigramModel():\n",
    "    def __init__(self, tokenizer):\n",
    "        self.unigram_model = defaultdict(int)\n",
    "        self.word_count = 0\n",
    "        self.vocab_count = 0\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "    def tokenize_subwords(self, sent):\n",
    "        return [item.replace('Ġ', '') for item in self.tokenizer.tokenize(sent)]\n",
    "\n",
    "    def build(self, files, limit=None):\n",
    "        for file in tqdm(files[:limit]):\n",
    "            content = read_file(file)\n",
    "            for sent in sent_tokenize(content):\n",
    "                if len(sent) > 1024:\n",
    "                    continue\n",
    "                for word in self.tokenize_subwords(sent):\n",
    "                    token = word.lower()\n",
    "                    self.unigram_model[token] += 1\n",
    "           \n",
    "        self.word_count = sum(self.unigram_model.values())\n",
    "        self.vocab_count = len(self.unigram_model.keys())\n",
    "    \n",
    "    def prob(self, words):\n",
    "        probs = [self.prob_token(sub) for sub in self.tokenize_subwords(words)]\n",
    "        return reduce((lambda x, y: x * y), probs)\n",
    "        \n",
    "    def prob_token(self, token):\n",
    "        return (self.unigram_model[token]+1)/(self.word_count+1)\n",
    "    \n",
    "\n",
    "with open(f'{MODELS_DIR}/unigram-expace/model-v1.pkl','rb') as f:\n",
    "    uni_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "mysterious-period",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lm_scorer.models.auto import GPT2LMScorer\n",
    "\n",
    "gpt2_tokenizer_id = 'gpt2'\n",
    "gpt2_model_name = 'expace-v1'\n",
    "gpt2_model_id = f'{MODELS_DIR}gpt2-{gpt2_model_name}'\n",
    "\n",
    "scorer = GPT2LMScorer(gpt2_model_id, device='cuda:0', batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "divided-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slor(sent):\n",
    "    log_s = scorer.sentence_score(sent, log=True)\n",
    "    log_unigram_s = calculate_uni_prob(sent)\n",
    "    \n",
    "    return (log_s - log_unigram_s)/len(sent.split())\n",
    "\n",
    "\n",
    "def calculate_uni_prob(sentence):\n",
    "    return sum([math.log(uni_model.prob(token)) for token in word_tokenize(sentence.lower())])\n",
    "\n",
    "def process_slor(file, limit=None, detokenize=False, input_dir=MODEL_VERSION_RESULTS_DIR_PROCESSED, output_dir=MODEL_VERSION_RESULTS_DIR_METRICS, metric_version=None):\n",
    "    process_file_metric(file, slor, 'slor', limit=limit, detokenize=detokenize, input_dir=input_dir, output_dir=output_dir, metric_version=metric_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-durham",
   "metadata": {},
   "source": [
    "# Linguistic diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simalign import SentenceAligner\n",
    "\n",
    "sent_aligner = SentenceAligner(model=\"bert\", token_type=\"bpe\", matching_methods=\"i\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "working-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import hashlib\n",
    "import pickle\n",
    "import os\n",
    "from nltk import word_tokenize\n",
    "\n",
    "def align_sentence(sent1, sent2, method='itermax'):\n",
    "    file_name = hashlib.md5((sent1+'-'+sent2).encode('utf-8')).hexdigest()        \n",
    "    file_path = f'{ALIGNMENT_FOLDER}/{file_name}.pkl'\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            f.seek(0)\n",
    "            alignments = pickle.load(f)\n",
    "    else:\n",
    "        src_sentence = word_tokenize(sent1)\n",
    "        trg_sentence = word_tokenize(sent2)\n",
    "\n",
    "        alignments = sent_aligner.get_word_aligns(src_sentence, trg_sentence)\n",
    "        alignments = alignments[method]\n",
    "        with open(file_path, 'wb') as f:\n",
    "            pickle.dump(alignments, f)\n",
    "    \n",
    "    return alignments\n",
    "\n",
    "def get_sentences_same_alignment(pairs):\n",
    "    selected = []\n",
    "    \n",
    "    index = 0\n",
    "    for pair in tqdm.tqdm(pairs):      \n",
    "        alignments = align_sentence(pair['orig'], pair['improved'][0])        \n",
    "        if all([item[0] == item[1] for item in alignments]):            \n",
    "            selected.append(pair)\n",
    "            \n",
    "        index += 1\n",
    "    return selected\n",
    "\n",
    "def process_alignment(pairs):\n",
    "    alignments = []\n",
    "    \n",
    "    index = 0\n",
    "    for pair in tqdm.tqdm(pairs):      \n",
    "        alignments.append(align_sentence(pair['orig'], pair['improved'][0]))\n",
    "    return alignments\n",
    "\n",
    "def get_aligned_sentences(sentences):\n",
    "    return list(zip(sentences, process_alignment(sentences)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "effective-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "wn_lemmas = set(wordnet.all_lemma_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "blank-marketplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syntactical_diversity(sent1, sent2, version=None):\n",
    "    alignment = align_sentence(sent1, sent2)\n",
    "    sum_diff = sum([abs(item[0]-item[1]) for item in alignment])\n",
    "    if version == 'v1':\n",
    "        return sum_diff/math.sqrt(len(alignment))\n",
    "    else:\n",
    "        return sum_diff/len(alignment)\n",
    "\n",
    "def lexical_diversity(sent1, sent2, return_diffs=False, version=None):\n",
    "    alignment = align_sentence(sent1, sent2)\n",
    "    src_sentence = word_tokenize(sent1)\n",
    "    trg_sentence = word_tokenize(sent2)\n",
    "\n",
    "    diff_count = 0\n",
    "    total = 0\n",
    "    \n",
    "    diffs = []\n",
    "    for align in alignment:\n",
    "        word1 = src_sentence[align[0]]\n",
    "        word2 = trg_sentence[align[1]]\n",
    "    \n",
    "        if word1 == word2:\n",
    "            continue\n",
    "            \n",
    "        total+=1\n",
    "        \n",
    "        lemma_orig = wordnet_lemmatizer.lemmatize(word1)\n",
    "        lemma_repl = wordnet_lemmatizer.lemmatize(word2)\n",
    "        \n",
    "        if lemma_orig not in wn_lemmas or lemma_repl not in wn_lemmas:\n",
    "            continue\n",
    "            \n",
    "        if lemma_orig != lemma_repl:\n",
    "            diffs.append([lemma_orig, lemma_repl])\n",
    "            diff_count += 1\n",
    "    score = 0\n",
    "    \n",
    "    if total > 0:\n",
    "        if version == 'v1':\n",
    "            score = (diff_count)/len(trg_sentence)\n",
    "        elif version == 'v2':\n",
    "            score = (diff_count)/math.sqrt(len(trg_sentence))\n",
    "        else:\n",
    "            score = (diff_count)/total\n",
    "    if return_diffs:\n",
    "        return score, diffs\n",
    "    \n",
    "    return score\n",
    "\n",
    "def process_syntax(file1, file2, limit=None, detokenize=False, output='syntax', input_dir=MODEL_VERSION_RESULTS_DIR_PROCESSED, output_dir=MODEL_VERSION_RESULTS_DIR_METRICS, metric_version=None):\n",
    "    process_metric_paired(file1, file2, lambda x1, x2: syntactical_diversity(x1, x2, version=metric_version), output, limit=limit, detokenize=detokenize, input_dir=input_dir, output_dir=output_dir, metric_version=metric_version)\n",
    "    \n",
    "def process_lexical(file1, file2, limit=None, detokenize=False, output='lexical', input_dir=MODEL_VERSION_RESULTS_DIR_PROCESSED, output_dir=MODEL_VERSION_RESULTS_DIR_METRICS, metric_version=None):\n",
    "    process_metric_paired(file1, file2, lambda x1, x2: lexical_diversity(x1, x2, version=metric_version), output, limit=limit, detokenize=detokenize, input_dir=input_dir, output_dir=output_dir, metric_version=metric_version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assumed-mattress",
   "metadata": {},
   "source": [
    "## Evaluate files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize \n",
    "import torch\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "import os\n",
    "\n",
    "def process_file_metric(file, metric, metric_name, limit=None, detokenize=False, input_dir=MODEL_VERSION_RESULTS_DIR_PROCESSED, output_dir=MODEL_VERSION_RESULTS_DIR_METRICS, metric_version=None):    \n",
    "    if metric_version:\n",
    "        output_file = f'{output_dir}/{metric_name}-{metric_version}-{file}'\n",
    "    else:\n",
    "        output_file = f'{output_dir}/{metric_name}-{file}'\n",
    "        \n",
    "    if os.path.exists(output_file):\n",
    "        print ('=> Already processed', f'{file}')\n",
    "        return\n",
    "    if not os.path.exists(f'{input_dir}/{file}'):\n",
    "        print ('=> Skipping', f'{file}')\n",
    "        return\n",
    "        \n",
    "    perplexities = []\n",
    "    with open(f'{input_dir}/{file}', 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in tqdm(lines[:limit]):\n",
    "            line = line.strip()\n",
    "            if detokenize:\n",
    "                line = TreebankWordDetokenizer().detokenize(word_tokenize(line))\n",
    "                \n",
    "            perplexities.append(metric(line))\n",
    "    \n",
    "        \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(map(str, perplexities)))\n",
    "        \n",
    "def process_metric_paired(file1, file2, metric, metric_name, limit=None, detokenize=False, input_dir=MODEL_VERSION_RESULTS_DIR_PROCESSED, output_dir=MODEL_VERSION_RESULTS_DIR_METRICS, metric_version=None):    \n",
    "    selected_file = file2.replace('-improved','')\n",
    "    if metric_version:\n",
    "        output_file = f'{output_dir}/{metric_name}-{metric_version}-{selected_file}'\n",
    "    else:\n",
    "        output_file = f'{output_dir}/{metric_name}-{selected_file}'\n",
    "        \n",
    "    if os.path.exists(output_file):\n",
    "        print ('=> Already processed', f'{metric_name}')\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(f'{input_dir}/{file1}'):\n",
    "        print ('=> Skipping', f'{file1}')\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists(f'{input_dir}/{file2}'):\n",
    "        print ('=> Skipping', f'{file2}')\n",
    "        return\n",
    "        \n",
    "    metrics = []\n",
    "    \n",
    "    with open(f'{input_dir}/{file1}', encoding='utf8') as f1, open(f'{input_dir}/{file2}', encoding='utf8') as f2: \n",
    "        lines1 = f1.readlines()\n",
    "        lines2 = f2.readlines()\n",
    "        \n",
    "        for sent1, sent2 in tqdm.tqdm(list(zip(lines1[:limit], lines2[:limit]))):\n",
    "            sent1 = sent1.strip()\n",
    "            sent2 = sent2.strip()\n",
    "            \n",
    "            metrics.append(metric(sent1, sent2))        \n",
    "    \n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(map(str, metrics)))    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-christian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "LANGUAGES_MULTI = ['pt', 'es']\n",
    "\n",
    "multi_lingual_files = [   \n",
    "    'brace-v1-20000.json',      \n",
    "    'lace-v1-20000.json',     \n",
    "]\n",
    "\n",
    "multi_lingual_token_files = get_multi_tokens(multi_lingual_files, LANGUAGES_MULTI)\n",
    "\n",
    "models_list = [\n",
    "    'gector-v5',\n",
    "]\n",
    "\n",
    "models_multi_list = [\n",
    "    't5lg-l1aware-multi-s260-v1',\n",
    "    't5sm-l1aware-multi-s260-v1',    \n",
    "]\n",
    "\n",
    "def process_multimodel(models, files, types=['orig', 'improved'], metric='perplexity', metric_version=None, limit=None):   \n",
    "    for model_version in models:\n",
    "        print ('=> Model', model_version)\n",
    "        input_folder = f'{RESULTS_DIR}{MODEL_NAME}/{model_version}/processed/'\n",
    "        output_folder = f'{RESULTS_DIR}{MODEL_NAME}/{model_version}/metrics/'\n",
    "        pathlib.Path(output_folder).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for file in files:\n",
    "            print ('====> Current', file)\n",
    "            base_file = file.split('.')[0]\n",
    "            for kind in types:\n",
    "                if metric == 'perplexity':\n",
    "                    process_perplexity(base_file+f'-{kind}.txt', input_dir=input_folder, output_dir=output_folder, metric_version=metric_version, limit=limit)\n",
    "                elif metric == 'slor':\n",
    "                    process_slor(base_file+f'-{kind}.txt', input_dir=input_folder, output_dir=output_folder, metric_version=metric_version, limit=limit)                    \n",
    "                elif metric == 'grammar':\n",
    "                    process_grammaticality(base_file+f'-{kind}.txt', input_dir=input_folder, output_dir=output_folder, metric_version=metric_version, limit=limit)                    \n",
    "            \n",
    "            if metric == 'lexical':\n",
    "                process_lexical(base_file+f'-orig.txt', base_file+f'-improved.txt', input_dir=input_folder, output_dir=output_folder, metric_version=metric_version, limit=limit)                    \n",
    "            elif metric == 'syntax':\n",
    "                process_syntax(base_file+f'-orig.txt', base_file+f'-improved.txt', input_dir=input_folder, output_dir=output_folder, metric_version=metric_version, limit=limit)                    \n",
    "        print()\n",
    "            \n",
    "\n",
    "metric_version = None\n",
    "PROCESS_LIMIT = None\n",
    "\n",
    "for metric in ['lexical', 'grammar', 'lexical', 'syntactical']:\n",
    "    process_multimodel(models_list, multi_lingual_files, metric=metric, limit=PROCESS_LIMIT, metric_version=metric_version)\n",
    "    process_multimodel(models_multi_list, multi_lingual_token_files, metric=metric,limit=PROCESS_LIMIT, metric_version=metric_version)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
